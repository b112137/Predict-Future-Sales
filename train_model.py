# -*- coding: utf-8 -*-
"""Train Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tNyyxK4XIWDBQC5QQYBlYtOVRzlEAyVA

# Load Data
"""

import os
import pandas as pd
import numpy as np
import seaborn as sns
from matplotlib import pyplot as plt
from sklearn.preprocessing import LabelEncoder
import lightgbm as lgb
from catboost import CatBoostRegressor
from sklearn.metrics import mean_squared_error
import xgboost as xgb

"""# Train model"""

df_all = pd.read_csv("df_all.csv")

X_train = df_all[df_all.date_block_num < 33].drop(['item_cnt_month'], axis=1)
Y_train = df_all[df_all.date_block_num < 33]['item_cnt_month']
X_valid = df_all[df_all.date_block_num == 33].drop(['item_cnt_month'], axis=1)
Y_valid = df_all[df_all.date_block_num == 33]['item_cnt_month']
X_test = df_all[df_all.date_block_num == 34].drop(['item_cnt_month'], axis=1)

params = {
    'objective': 'mse',
    'metric': 'rmse',
    'num_leaves': 2 ** 7 - 1,
    'learning_rate': 0.005,
    'feature_fraction': 0.75,
    'bagging_fraction': 0.75,
    'bagging_freq': 5,
    'seed': 1,
    'verbose': 1
}

categorical_feature = ['shop_id','item_id','shop_city','item_category_id','item_category_split']

lgb_train_data = lgb.Dataset(X_train[X_train.columns.tolist()], Y_train)
lgb_eval_data = lgb.Dataset(X_valid[X_train.columns.tolist()], Y_valid, reference=lgb_train_data)

evals_result = {}
gbm = lgb.train(
        params, 
        lgb_train_data,
        num_boost_round=1000,
        valid_sets=(lgb_train_data, lgb_eval_data), 
        feature_name = X_train.columns.tolist(),
        categorical_feature = categorical_feature,
        verbose_eval=5, 
        evals_result = evals_result,
        early_stopping_rounds = 50)

lgb.plot_importance(
    gbm, 
    max_num_features=50, 
    importance_type='gain', 
    figsize=(12,8));

test = pd.read_csv('test.csv')
Y_test = gbm.predict(X_test[X_train[X_train.columns.tolist()]]).clip(0, 20)

submission = pd.DataFrame({
    "ID": test.index, 
    "item_cnt_month": Y_test
})
submission.to_csv('gbm_submission.csv', index=False)



# Initialize data

train_data = X_train[X_train.columns.tolist()]

eval_data = X_valid[X_train.columns.tolist()]

train_labels = Y_train
# Initialize CatBoostRegressor
model = CatBoostRegressor(iterations=150,
                          learning_rate=1,
                          depth=8)
# Fit model
model.fit(train_data, train_labels)

preds=model.predict(train_data)

mean_squared_error(preds, train_labels )

# Get predictions
preds = model.predict(eval_data)

mean_squared_error(preds, Y_valid )

test = pd.read_csv('test.csv')
Y_test = model.predict(X_test[X_train.columns.tolist()]).clip(0, 20)

submission = pd.DataFrame({
    "ID": test.index, 
    "item_cnt_month": Y_test
})
submission.to_csv('cat_submission.csv', index=False)




train_data = X_train[X_train.columns.tolist()]
eval_data = X_valid[X_train.columns.tolist()]
train_labels = Y_train


xgbrModel=xgb.XGBRegressor(verbosity=2, max_leaves=6)
xgbrModel.fit(train_data,train_labels)

preds=xgbrModel.predict(train_data)

mean_squared_error(preds, train_labels )

preds=xgbrModel.predict(eval_data)

mean_squared_error(preds, Y_valid )

test = pd.read_csv('test.csv')
Y_test = xgbrModel.predict(X_test[X_train.columns.tolist()])

submission = pd.DataFrame({
    "ID": test.index, 
    "item_cnt_month": Y_test
})
submission.to_csv('xgboost_submission.csv', index=False)



"""# Ensemble"""

gbm_df = pd.read_csv("gbm_submission_0.709847_0.916429_0.95215.csv")
cat_df = pd.read_csv("cat_submission_0.689545_0.965963_0.98166.csv")
xgb_df = pd.read_csv("xgboost_submission_0.905395_0.918857_0.98376.csv")

Y_test = 0.6*gbm_df["item_cnt_month"] + 0.2*cat_df["item_cnt_month"] + 0.2*xgb_df["item_cnt_month"]

submission = pd.DataFrame({
    "ID": test.index, 
    "item_cnt_month": Y_test
})
submission.to_csv('submission.csv', index=False)









